{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LMDeploy环境搭建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LMDeploy介绍\n",
    "书生浦语首页网址：\n",
    "[书生浦语](https://internlm.intern-ai.org.cn/)\n",
    "\n",
    "中文使用说明网址：\n",
    "[中文使用说](https://lmdeploy.readthedocs.io/zh-cn/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 硬件要求\n",
    "\n",
    "![硬件要求](Image/2025-03-26-20-52-46.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 官网安装方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![官网安装方法](Image/2025-03-26-20-59-29.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "执行一下命令进行安装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conda create -n lmdeploy python=3.8 -y\n",
    "conda activate lmdeploy\n",
    "pip install lmdeploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开启LLM 模型服务\n",
    "开启方法：\n",
    "lmdeploy serve api_server +模型路径\n",
    "\n",
    "例如：\n",
    "\n",
    "lmdeploy serve api_server internlm/internlm2_5-7b-chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开启千问模型的服务\n",
    "\n",
    "lmdeploy serve api_server /root/autodl-tmp/model/Qwen/Qwen2.5-0.5B-Instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果报错则安装缺少的东西\n",
    "\n",
    "![](Image/2025-03-26-22-11-23.png)\n",
    "\n",
    "![](Image/2025-03-26-22-23-36.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "端口号默认：23333，代码需要修改端口号和模型路径\n",
    "\n",
    "![](Image/2025-03-26-22-12-37.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Image/2025-03-26-22-24-03.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#多轮对话\n",
    "from openai import OpenAI\n",
    "\n",
    "#定义多轮对话方法\n",
    "def run_chat_session():\n",
    "    #初始化客户端\n",
    "    client = OpenAI(base_url=\"http://localhost:23333/v1/\",api_key=\"suibianxie\")\n",
    "    #初始化对话历史\n",
    "    chat_history = []\n",
    "    #启动对话循环\n",
    "    while True:\n",
    "        #获取用户输入\n",
    "        user_input = input(\"用户：\")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"退出对话。\")\n",
    "            break\n",
    "        #更新对话历史(添加用户输入)\n",
    "        chat_history.append({\"role\":\"user\",\"content\":user_input})\n",
    "        #调用模型回答\n",
    "        try:\n",
    "            chat_complition = client.chat.completions.create(messages=chat_history,model=\"/root/autodl-tmp/model/Qwen/Qwen2.5-0.5B-Instruct\")\n",
    "            #获取最新回答\n",
    "            model_response = chat_complition.choices[0]\n",
    "            print(\"AI:\",model_response.message.content)\n",
    "            #更新对话历史（添加AI模型的回复）\n",
    "            chat_history.append({\"role\":\"assistant\",\"content\":model_response.message.content})\n",
    "        except Exception as e:\n",
    "            print(\"发生错误：\",e)\n",
    "            break\n",
    "if __name__ == '__main__':\n",
    "    run_chat_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.LoRA微调的基本原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本概念\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " LoRA（Low-Rank Adaptation）是一种用于大模型微调的技术，通过引入低秩矩阵来减少微调时的参数量。在预训练的模型中，LoRA通过添加两个小矩阵B和A来近似原始的大矩阵ΔW，从而减少需要更新的参数数量。具体来说，LoRA通过将全参微调的增量参数矩阵ΔW表示为两个参数量更小的矩阵B和A的低秩近似来实现：\n",
    " [ W_0 + \\Delta W = W_0 + BA ]\n",
    " 其中，B和A的秩远小于原始矩阵的秩，从而大大减少了需要更新的参数数量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 思想"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预训练模型中存在一个极小的内在维度，这个内在维度是发挥核心作用的地方。在继续训练的过程中，权重的更新依然也有如此特点，即也存在一个内在维度(内在秩)\n",
    " • 权重更新:W=W+^W\n",
    " • 因此，可以通过矩阵分解的方式，将原本要更新的大的矩阵变为两个小的矩阵\n",
    " • 权重更新:W=W+^W=W+BA\n",
    " • 具体做法，即在矩阵计算中增加一个旁系分支，旁系分支由两个低秩矩阵A和B组成\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• 训练时，输入分别与原始权重和两个低秩矩阵进行计算，共同得到最终结果，优化则仅优化A和B\n",
    "• 训练完成后，可以将两个低秩矩阵与原始模型中的权重进行合并，合并后的模型与原始模型无异\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Image/2025-03-26-23-27-22.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.LLaMA-Factory介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[LLaMA-Factory Github介绍](https://github.com/hiyouga/LLaMA-Factory/blob/main/README_zh.md)\n",
    "\n",
    "[LLaMA-Factory官方保姆级教程](https://blog.csdn.net/python12345678_/article/details/140346926)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 项目特色\n",
    "多种模型：LLaMA、LLaVA、Mistral、Mixtral-MoE、Qwen、Qwen2-VL、DeepSeek、Yi、Gemma、ChatGLM、Phi 等等。\n",
    "集成方法：（增量）预训练、（多模态）指令监督微调、奖励模型训练、PPO 训练、DPO 训练、KTO 训练、ORPO 训练等等。\n",
    "多种精度：16 比特全参数微调、冻结微调、LoRA 微调和基于 AQLM/AWQ/GPTQ/LLM.int8/HQQ/EETQ 的 2/3/4/5/6/8 比特 QLoRA 微调。\n",
    "先进算法：GaLore、BAdam、APOLLO、Adam-mini、DoRA、LongLoRA、LLaMA Pro、Mixture-of-Depths、LoRA+、LoftQ 和 PiSSA。\n",
    "实用技巧：FlashAttention-2、Unsloth、Liger Kernel、RoPE scaling、NEFTune 和 rsLoRA。\n",
    "广泛任务：多轮对话、工具调用、图像理解、视觉定位、视频识别和语音理解等等。\n",
    "实验监控：LlamaBoard、TensorBoard、Wandb、MLflow、SwanLab 等等。\n",
    "极速推理：基于 vLLM 或 SGLang 的 OpenAI 风格 API、浏览器界面和命令行接口。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 软硬件依赖"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Image/2025-03-26-23-41-36.png) ![](Image/2025-03-26-23-41-58.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Image/2025-03-26-23-45-00.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Image/2025-03-26-23-48-04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\n",
    "新建虚拟环境再执行下面的指令\n",
    "cd LLaMA-Factory\n",
    "pip install -e \".[torch,metrics]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Image/2025-03-26-23-54-15.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conda create -n llamafactory python==3.10 -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Image/2025-03-26-23-59-14.png)\n",
    "\n",
    "激活虚拟环境\n",
    "\n",
    "![](Image/2025-03-26-23-59-42.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以先装基础环境，不装\".[torch,metrics]\"的东西"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Image/2025-03-27-00-02-57.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "安装完成\n",
    "\n",
    "![](Image/2025-03-27-00-14-48.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.使用 LLaMA-Factory 微调 Qwen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 更改助手名称\n",
    "可以将identity.json下载到本地，然后将{{name}}替换为想要的名称重新上传"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Image/2025-03-27-00-13-14.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 启动服务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Image/2025-03-27-00-16-42.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "llamafactory-cli webui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "执行完成后会跳转到浏览器，注意是采用VScode链接远程服务器，如果换其他方法不一定可以\n",
    "\n",
    "![](Image/2025-03-27-00-19-33.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打开dataset_info.json，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Image/2025-03-27-00-27-57.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Image/2025-03-27-00-33-37.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面几个自动适应，一般不用改"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Image/2025-03-27-00-35-34.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Image/2025-03-27-00-38-46.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选择数据集\n",
    "\n",
    "![](Image/2025-03-27-00-42-43.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预览数据集确认是否正确"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Image/2025-03-27-00-41-24.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练轮数不能太小，至少要大于300\n",
    "\n",
    "![](Image/2025-03-27-00-45-49.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "截断长度即maxlength，给长了会占用显存，给的值小会减少显存占用，但是要保证满足回复长度的需求\n",
    "\n",
    "![](Image/2025-03-27-00-50-21.png)\n",
    "\n",
    "![](Image/2025-03-27-00-49-40.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "批处理大小即批次，要根据显存大小来调\n",
    "\n",
    "![](Image/2025-03-27-00-52-35.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“验证集比例”要设置一下，另外两个不用管\n",
    "\n",
    "![](Image/2025-03-27-00-54-09.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般“LoRA 缩放系数”是“LoRA 秩”的两倍，具体怎么调需要技巧，后面再说\n",
    "\n",
    "![](Image/2025-03-27-00-55-44.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“设备数量”指的是有几张卡，“配置路径”指的是我们上面设置的参数保存位置\n",
    "\n",
    "![](Image/2025-03-27-00-58-05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "点击开始\n",
    "\n",
    "![](Image/2025-03-27-01-04-13.png)\n",
    "\n",
    "如果出现RuntimeError:CUDA error:out of memory,要减小批次，或者检查是否有其他地方占用显存比较严重，比如说还开了其他模型\n",
    "\n",
    "![](Image/2025-03-27-01-03-30.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Num examples是计算出来的样本数量\n",
    "\n",
    "![](Image/2025-03-27-01-11-31.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "批次大小要根据显存占用情况来调，如果显存占用比较低可以增大批次\n",
    "\n",
    "![](Image/2025-03-27-01-17-43.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "点击中断\n",
    "\n",
    "![](Image/2025-03-27-01-18-30.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "等待准备就绪\n",
    "\n",
    "![](Image/2025-03-27-01-28-40.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改批次大小重新开始，一直调到显存占用90%左右\n",
    "\n",
    "![](Image/2025-03-27-01-20-12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "权重保存位置如下，默认是100个epoch保存一次权重,可以在浏览器中进行更改\n",
    "\n",
    "![](Image/2025-03-27-01-37-06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“日志间隔”是在终端每5个epoch输出一次，“保存间隔”是每100个epoch保存一次权重\n",
    "\n",
    "![](Image/2025-03-27-01-39-28.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证集和保存权重同步，所以保存间隔也控制验证\n",
    "\n",
    "![](Image/2025-03-27-01-46-11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 继续训练的方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，在界面中点击中断和开始就是继续训练\n",
    "\n",
    "![](Image/2025-03-27-01-51-32.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是如果出现界面崩掉的情况，继续训练就要手动设置，比如说我已经有了一个权重\n",
    "\n",
    "![](Image/2025-03-27-01-53-14.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将权重设置到“检查点路径”中，然后开始就行\n",
    "\n",
    "![](Image/2025-03-27-01-54-20.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练完成验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 不加载权重的情况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不加载权重模型会按照以前的知识来介绍自己"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Image/2025-03-27-02-02-32.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Image/2025-03-27-02-03-52.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载权重后测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Image/2025-03-27-02-07-18.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
